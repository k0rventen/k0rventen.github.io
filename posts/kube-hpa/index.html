<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Exploring Kube&#39;s Horizontal Pod Autoscaler | k0rventen&#39;s blog</title>
<meta name="keywords" content="k8s, hpa, scaling">
<meta name="description" content="scale your microservices based on CPU usage">
<meta name="author" content="">
<link rel="canonical" href="/posts/kube-hpa/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk&#43;4bvpN&#43;sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as="style">
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="/posts/kube-hpa/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="/posts/kube-hpa/">
  <meta property="og:site_name" content="k0rventen&#39;s blog">
  <meta property="og:title" content="Exploring Kube&#39;s Horizontal Pod Autoscaler">
  <meta property="og:description" content="scale your microservices based on CPU usage">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2021-07-27T00:00:00+00:00">
    <meta property="article:modified_time" content="2021-07-27T00:00:00+00:00">
    <meta property="article:tag" content="K8s">
    <meta property="article:tag" content="Hpa">
    <meta property="article:tag" content="Scaling">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Exploring Kube&#39;s Horizontal Pod Autoscaler">
<meta name="twitter:description" content="scale your microservices based on CPU usage">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "/posts/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Exploring Kube's Horizontal Pod Autoscaler",
      "item": "/posts/kube-hpa/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Exploring Kube's Horizontal Pod Autoscaler",
  "name": "Exploring Kube\u0027s Horizontal Pod Autoscaler",
  "description": "scale your microservices based on CPU usage",
  "keywords": [
    "k8s", "hpa", "scaling"
  ],
  "articleBody": "what \u0026 why Let’s say you have a scalable architecture (like a server/worker model), and you want autoscaling to happens automatically based on the workers CPU usage, which is useful is some scenarios. Kubernetes has an Horizontal Pod Autoscaler feature that we can utilize to do just that !\nhow First, let’s talk requirements. You’ll need :\na k8s cluster (k0s, minikube or microk8s), kubectl installed and configured to talk to your cluster metrics-server deployed. This will provide the metrics necessary for the autoscaling algorithm to work. Check on your particular provider how to do so. example architecture Here is an example architecture that can benefit from scaling :\na server that sends out jobs X workers that do_work() when receiving a job a way for the server to communicate with the workers, a message queue for example. In our demo, we have the following resources running on a k8s cluster :\na rabbitmq deployment, with a rabbitmq service.\na server deployment, based on k0rventen/hpa-server, with the following logic:\nimport time, json from random import choices, randint from string import ascii_letters import pika QUEUE_NAME = \"foo\" connection = pika.BlockingConnection(pika.ConnectionParameters('rabbitmq')) channel = connection.channel() channel.queue_declare(queue=QUEUE_NAME) if __name__ == \"__main__\": while True: obj = {\"payload\":\"\".join(choices(ascii_letters,k=10))} channel.basic_publish(exchange=\"\", routing_key=QUEUE_NAME,body=json.dumps(obj)) time.sleep(randint(1,11)/10) It basically connects to the rabbitmq broker, declare a new foo queue, and then sends message to that queue forever, every .1 to 1s (which averages to around .5s).\na worker deployment, running k0rventen/hpa-worker, with this code :\nimport time, pika QUEUE_NAME = \"foo\" connection = pika.BlockingConnection(pika.ConnectionParameters('rabbitmq')) channel = connection.channel() def callback(ch, method, properties, body): t0 = time.time() while time.time() \u003c t0+.8: # work for .8s, which is a bit more than the interval between jobs sent by the server 1*1 ch.basic_ack(delivery_tag = method.delivery_tag) if __name__ == \"__main__\": channel.basic_consume(queue=QUEUE_NAME,on_message_callback=callback) channel.start_consuming() the worker connects to the queue declared by the server, and for each message, it works for .8s.\nThe worker takes around .8s to process the job. Based on how many jobs per second are sent by the server, we might run into a situation where the worker is overloaded, and can’t keep up. Jobs will just pile up, and that’s not good. But it’s also pointless to just scale the workers manually, eg k scale deploy worker --replicas 6, and have too many instances just waiting when no jobs are sent, but 6 might be not enough if we encounter a spike in usage.\nTo follow along, create the following resources :\n# namespace k create ns hpa # rabbitmq message bus k create -n hpa deploy rabbitmq --image rabbitmq:3-management --port 5672 --port 15672 k expose -n hpa deploy/rabbitmq --port 5672 --target-port 5672 # server k create -n hpa deploy server --image=k0rventen/hpa-server # worker k create -n hpa deploy worker --image=k0rventen/hpa-worker we can now connect to the rabbitmq ui using k port-forward -n hpa deploy/rabbitmq 15672:15672 and opening localhost:15672.\nHPA based on CPU usage For the autoscaling to work, we need to specify what cpu usage percent is considered a threshold to spawn new instances. With metric-server, we have the raw cpu usage for each pod (let say our worker consume 900m cpu). But that doesn’t translate into percentage until we specify limits for our containers. For that, we’ll edit the worker deployment, and add resource limits to the container spec:\nk edit deploy/worker -n hpa\n... spec: containers: - image: k0rventen/hpa-worker imagePullPolicy: Always name: hpa-worker resources: limits: memory: \"128Mi\" cpu: \"100m\" ... We are enforcing a limit of 100m cpu. The single worker will now be pinned at 100m CPU usage, which you can check via kz top pods -n hpa | grep worker.\nWe can now configure our HPA to scale the number of replicas of our worker deployment with the following settings :\nk autoscale -n hpa deploy worker --max 8 --min 1 --cpu-percent 50\n--min is the minimum number of replicas to have. --max is the maximum number of replicas to have. Note that this number may not be achieved due to resources constraints. A simple example is with a host having 2 CPUs (or 2000m CPU), and a worker consuming 200m CPU, you won’t be able to have more than 10 replicas. --cpu-percent is the percentage of CPU usage above which the autoscaler will add new instances (and vice-versa). We can check what the hpa is doing with kz describe hpa -n hpa worker :\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal SuccessfulRescale 4m18s horizontal-pod-autoscaler New size: 3; reason: cpu resource utilization (percentage of request) above target Normal SuccessfulRescale 2m33s horizontal-pod-autoscaler New size: 4; reason: cpu resource utilization (percentage of request) above target Normal SuccessfulRescale 33s horizontal-pod-autoscaler New size: 5; reason: cpu resource utilization (percentage of request) above target On the rabbitmq dashboard, we can see the number of messages queued going downhill since the activation of the HPA :\nAnd once the queued messages are all processed, the workers’s CPU usage will drop, and the HPA will decrease the number of replicas to match that level of load. In our case it might drop to 2 or 3 replicas :\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal SuccessfulRescale 24m horizontal-pod-autoscaler New size: 3; reason: cpu resource utilization (percentage of request) above target Normal SuccessfulRescale 22m horizontal-pod-autoscaler New size: 4; reason: cpu resource utilization (percentage of request) above target Normal SuccessfulRescale 20m horizontal-pod-autoscaler New size: 5; reason: cpu resource utilization (percentage of request) above target Normal SuccessfulRescale 8m30s horizontal-pod-autoscaler New size: 4; reason: All metrics below target Normal SuccessfulRescale 3m27s horizontal-pod-autoscaler New size: 3; reason: All metrics below target ",
  "wordCount" : "930",
  "inLanguage": "en",
  "datePublished": "2021-07-27T00:00:00Z",
  "dateModified": "2021-07-27T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/posts/kube-hpa/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "k0rventen's blog",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="&gt; k0rventen: ~ (Alt + H)">&gt; k0rventen: ~</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="/links" title="links">
                    <span>links</span>
                </a>
            </li>
            <li>
                <a href="/posts" title="posts">
                    <span>posts</span>
                </a>
            </li>
            <li>
                <a href="/search" title="search (Alt &#43; /)" accesskey=/>
                    <span>search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="/">Home</a>&nbsp;»&nbsp;<a href="/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Exploring Kube&#39;s Horizontal Pod Autoscaler
    </h1>
    <div class="post-description">
      scale your microservices based on CPU usage
    </div>
    <div class="post-meta"><span title='2021-07-27 00:00:00 +0000 UTC'>July 27, 2021</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;930 words

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#what--why">what &amp; why</a></li>
    <li><a href="#how">how</a></li>
    <li><a href="#example-architecture">example architecture</a></li>
    <li><a href="#hpa-based-on-cpu-usage">HPA based on CPU usage</a></li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="what--why">what &amp; why<a hidden class="anchor" aria-hidden="true" href="#what--why">#</a></h2>
<p>Let&rsquo;s say you have a scalable architecture (like a server/worker model), and you want autoscaling to happens automatically based on the workers CPU usage, which is useful is some scenarios. Kubernetes has an <code>Horizontal Pod Autoscaler</code> feature that we can utilize to do just that !</p>
<h2 id="how">how<a hidden class="anchor" aria-hidden="true" href="#how">#</a></h2>
<p>First, let&rsquo;s talk requirements. You&rsquo;ll need :</p>
<ul>
<li>a <code>k8s cluster</code> (k0s, minikube or microk8s),</li>
<li><code>kubectl</code> installed and configured to talk to your cluster</li>
<li><code>metrics-server</code> deployed. This will provide the metrics necessary for the autoscaling algorithm to work. Check on your particular provider how to do so.</li>
</ul>
<h2 id="example-architecture">example architecture<a hidden class="anchor" aria-hidden="true" href="#example-architecture">#</a></h2>
<p>Here is an example architecture that can benefit from scaling :</p>
<ul>
<li>a server that sends out jobs</li>
<li>X workers that do_work() when receiving a job</li>
<li>a way for the server to communicate with the workers, a message queue for example.</li>
</ul>
<p>In our demo, we have the following resources running on a k8s cluster :</p>
<ul>
<li>
<p>a <code>rabbitmq</code> deployment, with a <code>rabbitmq</code> service.</p>
</li>
<li>
<p>a <code>server</code> deployment, based on <code>k0rventen/hpa-server</code>, with the following logic:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">time</span><span class="o">,</span> <span class="nn">json</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">choices</span><span class="p">,</span> <span class="n">randint</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">string</span> <span class="kn">import</span> <span class="n">ascii_letters</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pika</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">QUEUE_NAME</span> <span class="o">=</span> <span class="s2">&#34;foo&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">connection</span> <span class="o">=</span> <span class="n">pika</span><span class="o">.</span><span class="n">BlockingConnection</span><span class="p">(</span><span class="n">pika</span><span class="o">.</span><span class="n">ConnectionParameters</span><span class="p">(</span><span class="s1">&#39;rabbitmq&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">channel</span> <span class="o">=</span> <span class="n">connection</span><span class="o">.</span><span class="n">channel</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">channel</span><span class="o">.</span><span class="n">queue_declare</span><span class="p">(</span><span class="n">queue</span><span class="o">=</span><span class="n">QUEUE_NAME</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">obj</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;payload&#34;</span><span class="p">:</span><span class="s2">&#34;&#34;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">choices</span><span class="p">(</span><span class="n">ascii_letters</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">))}</span>
</span></span><span class="line"><span class="cl">        <span class="n">channel</span><span class="o">.</span><span class="n">basic_publish</span><span class="p">(</span><span class="n">exchange</span><span class="o">=</span><span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">routing_key</span><span class="o">=</span><span class="n">QUEUE_NAME</span><span class="p">,</span><span class="n">body</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span>
</span></span></code></pre></div><p>It basically connects to the rabbitmq broker, declare a new <code>foo</code> queue, and then sends message to that queue forever, every .1 to 1s (which averages to around .5s).</p>
</li>
<li>
<p>a <code>worker</code> deployment, running <code>k0rventen/hpa-worker</code>, with this code :</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">time</span><span class="o">,</span> <span class="nn">pika</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">QUEUE_NAME</span> <span class="o">=</span> <span class="s2">&#34;foo&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">connection</span> <span class="o">=</span> <span class="n">pika</span><span class="o">.</span><span class="n">BlockingConnection</span><span class="p">(</span><span class="n">pika</span><span class="o">.</span><span class="n">ConnectionParameters</span><span class="p">(</span><span class="s1">&#39;rabbitmq&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">channel</span> <span class="o">=</span> <span class="n">connection</span><span class="o">.</span><span class="n">channel</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">callback</span><span class="p">(</span><span class="n">ch</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">properties</span><span class="p">,</span> <span class="n">body</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">while</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">t0</span><span class="o">+</span><span class="mf">.8</span><span class="p">:</span> <span class="c1"># work for .8s, which is a bit more than the interval between jobs sent by the server</span>
</span></span><span class="line"><span class="cl">        <span class="mi">1</span><span class="o">*</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="n">ch</span><span class="o">.</span><span class="n">basic_ack</span><span class="p">(</span><span class="n">delivery_tag</span> <span class="o">=</span> <span class="n">method</span><span class="o">.</span><span class="n">delivery_tag</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">channel</span><span class="o">.</span><span class="n">basic_consume</span><span class="p">(</span><span class="n">queue</span><span class="o">=</span><span class="n">QUEUE_NAME</span><span class="p">,</span><span class="n">on_message_callback</span><span class="o">=</span><span class="n">callback</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">channel</span><span class="o">.</span><span class="n">start_consuming</span><span class="p">()</span>
</span></span></code></pre></div><p>the worker connects to the queue declared by the server, and for each message, it <em>works</em> for .8s.</p>
</li>
</ul>
<p>The worker takes around .8s to process the job. Based on how many jobs per second are sent by the server, we might run into a situation where the worker is overloaded, and can&rsquo;t keep up. Jobs will just pile up, and that&rsquo;s not good. But it&rsquo;s also pointless to just scale the workers manually, eg <code>k scale deploy worker --replicas 6</code>, and have <em>too many</em> instances just waiting when no jobs are sent, but 6 might be not enough if we encounter a spike in usage.</p>
<p>To follow along, create the following resources :</p>
<pre tabindex="0"><code># namespace
k create ns hpa

# rabbitmq message bus
k create -n hpa deploy rabbitmq --image rabbitmq:3-management --port 5672 --port 15672
k expose -n hpa deploy/rabbitmq --port 5672 --target-port 5672

# server
k create -n hpa deploy server --image=k0rventen/hpa-server

# worker
k create -n hpa deploy worker --image=k0rventen/hpa-worker
</code></pre><p>we can now connect to the rabbitmq ui using <code>k port-forward -n hpa deploy/rabbitmq 15672:15672</code> and opening <code>localhost:15672</code>.</p>
<h2 id="hpa-based-on-cpu-usage">HPA based on CPU usage<a hidden class="anchor" aria-hidden="true" href="#hpa-based-on-cpu-usage">#</a></h2>
<p>For the autoscaling to work, we need to specify what cpu usage percent is considered a threshold to spawn new instances. With metric-server, we have the raw cpu usage for each pod (let say our worker consume 900m cpu). But that doesn&rsquo;t translate into percentage until we specify limits for our containers. For that, we&rsquo;ll edit the worker deployment, and add resource limits to the container spec:</p>
<p><code>k edit deploy/worker -n hpa</code></p>
<pre tabindex="0"><code>    ...
    spec:
      containers:
      - image: k0rventen/hpa-worker
        imagePullPolicy: Always
        name: hpa-worker
        resources:
          limits:
            memory: &#34;128Mi&#34;
            cpu: &#34;100m&#34;
      ...
</code></pre><p>We are enforcing a limit of 100m cpu. The single worker will now be pinned at 100m CPU usage, which you can check via <code>kz top pods -n hpa | grep worker</code>.</p>
<p>We can now configure our HPA to scale the number of replicas of our <code>worker</code> deployment with the following settings :</p>
<p><code>k autoscale -n hpa deploy worker --max 8 --min 1 --cpu-percent 50</code></p>
<ul>
<li><code>--min</code> is the minimum number of replicas to have.</li>
<li><code>--max</code> is the maximum number of replicas to have. Note that this number may not be achieved due to resources constraints. A simple example is with a host having 2 CPUs (or 2000m CPU), and a worker consuming 200m CPU, you won&rsquo;t be able to have more than 10 replicas.</li>
<li><code>--cpu-percent</code> is the percentage of CPU usage above which the autoscaler will add new instances (and vice-versa).</li>
</ul>
<p>We can check what the hpa is doing with <code>kz describe hpa -n hpa worker</code> :</p>
<pre tabindex="0"><code>Events:
  Type    Reason             Age    From                       Message
  ----    ------             ----   ----                       -------
  Normal  SuccessfulRescale  4m18s  horizontal-pod-autoscaler  New size: 3; reason: cpu resource utilization (percentage of request) above target
  Normal  SuccessfulRescale  2m33s  horizontal-pod-autoscaler  New size: 4; reason: cpu resource utilization (percentage of request) above target
  Normal  SuccessfulRescale  33s    horizontal-pod-autoscaler  New size: 5; reason: cpu resource utilization (percentage of request) above target
</code></pre><p>On the rabbitmq dashboard, we can see the number of messages queued going downhill since the activation of the HPA :</p>
<p><img loading="lazy" src="/kube-hpa/rabbitmq.png"></p>
<p>And once the queued messages are all processed, the workers&rsquo;s CPU usage will drop, and the HPA will decrease the number of replicas to match that level of load. In our case it might drop to 2 or 3 replicas :</p>
<pre tabindex="0"><code>Events:
  Type    Reason             Age    From                       Message
  ----    ------             ----   ----                       -------
  Normal  SuccessfulRescale  24m    horizontal-pod-autoscaler  New size: 3; reason: cpu resource utilization (percentage of request) above target
  Normal  SuccessfulRescale  22m    horizontal-pod-autoscaler  New size: 4; reason: cpu resource utilization (percentage of request) above target
  Normal  SuccessfulRescale  20m    horizontal-pod-autoscaler  New size: 5; reason: cpu resource utilization (percentage of request) above target
  Normal  SuccessfulRescale  8m30s  horizontal-pod-autoscaler  New size: 4; reason: All metrics below target
  Normal  SuccessfulRescale  3m27s  horizontal-pod-autoscaler  New size: 3; reason: All metrics below target
</code></pre>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="/tags/k8s/">K8s</a></li>
      <li><a href="/tags/hpa/">Hpa</a></li>
      <li><a href="/tags/scaling/">Scaling</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="/posts/a-monkey-in-the-cluster/">
    <span class="title">« Prev</span>
    <br>
    <span>A Monkey in the Cluster</span>
  </a>
  <a class="next" href="/posts/remote-docker/">
    <span class="title">Next »</span>
    <br>
    <span>Remote Docker</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="/">k0rventen&#39;s blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
